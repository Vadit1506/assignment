{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LLM Fine-Tuning for Disease Suggestion from Symptoms\n", "Educational project notebook.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Install libraries"]}, {"cell_type": "code", "metadata": {}, "source": ["!pip install transformers datasets peft accelerate bitsandbytes"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Dataset"]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd\n", "df = pd.read_csv('DiseaseAndSymptoms.csv')\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Prepare JSONL"]}, {"cell_type": "code", "metadata": {}, "source": ["import json\n", "train = []\n", "for _, row in df.iterrows():\n", "    train.append({\n", "        'instruction': 'Identify the disease pattern based on symptoms.',\n", "        'input': row['Symptoms'],\n", "        'output': f\"Disease: {row['Disease']}\\nExplanation: Pattern from dataset.\\nNote: This is not medical advice.\"\n", "    })\n", "with open('train.jsonl','w') as f:\n", "    for ex in train:\n", "        f.write(json.dumps(ex)+'\\n')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Fine-Tune with QLoRA"]}, {"cell_type": "code", "metadata": {}, "source": ["from datasets import load_dataset\n", "dataset = load_dataset('json', data_files='train.jsonl', split='train')\n", "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n", "from peft import LoraConfig, get_peft_model\n", "\n", "model_id = 'google/gemma-2b'\n", "model = AutoModelForCausalLM.from_pretrained(model_id, device_map='auto')\n", "tokenizer = AutoTokenizer.from_pretrained(model_id)\n", "\n", "def preprocess(examples):\n", "    text = tokenizer('\n'.join([examples['instruction'], examples['input'], examples['output']]), truncation=True)\n", "    return text\n", "\n", "tokenized = dataset.map(preprocess)\n", "\n", "peft_config = LoraConfig(r=8, lora_alpha=16, target_modules=['q_proj','v_proj'], lora_dropout=0.05)\n", "model = get_peft_model(model, peft_config)\n", "\n", "args = TrainingArguments(\n", "    output_dir='finetuned',\n", "    per_device_train_batch_size=4,\n", "    num_train_epochs=2,\n", "    logging_steps=10\n", ")\n", "\n", "trainer = Trainer(model=model, args=args, train_dataset=tokenized)\n", "trainer.train()\n", "\n", "model.save_pretrained('adapter_out')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Confusion Matrix Placeholder (User must regenerate after training)"]}, {"cell_type": "code", "metadata": {}, "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "cm = np.array([[5,2],[1,7]])\n", "plt.imshow(cm)\n", "plt.title('Confusion Matrix (Placeholder)')\n", "plt.xlabel('Predicted')\n", "plt.ylabel('Actual')\n", "plt.savefig('/mnt/data/confusion_matrix.png')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 2}